
"""
LuxDB Example 06: Zaawansowane narzÄ™dzia
- Standaryzowane logowanie z DatabaseLogger
- ObsÅ‚uga bÅ‚Ä™dÃ³w i walidacja
- SQL Builder i szablony
- Przetwarzanie i filtrowanie danych
- Eksport/import w rÃ³Å¼nych formatach
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from manager import get_db_manager
from models import User, Log
from utils import (
    DatabaseLogger, get_db_logger, LuxDBError, handle_database_errors,
    SQLQueryBuilder, SQLTemplateEngine, SQLAnalyzer, execute_sql_safely,
    DataFilter, DataTransformer, DataAggregator, DataValidator, DataCleaner,
    DataExporter, DataImporter, ExportFormat, create_data_summary
)
from datetime import datetime, timedelta
import json
import tempfile

def setup_test_data():
    """Przygotuj dane testowe"""
    db = get_db_manager()
    
    # UtwÃ³rz bazÄ™ testowÄ…
    if not db.create_database("tools_demo"):
        print("âŒ Nie udaÅ‚o siÄ™ utworzyÄ‡ bazy testowej")
        return False
    
    # UtwÃ³rz tabele
    db.create_table_from_model("tools_demo", User)
    db.create_table_from_model("tools_demo", Log)
    
    # Dodaj testowych uÅ¼ytkownikÃ³w
    test_users = [
        {"username": "alice", "email": "alice@company.com", "password_hash": "hash1", "is_active": True, "phone": "123-456-789"},
        {"username": "bob", "email": "bob@external.com", "password_hash": "hash2", "is_active": True, "phone": "987-654-321"},
        {"username": "charlie", "email": "charlie@company.com", "password_hash": "hash3", "is_active": False, "phone": None},
        {"username": "diana", "email": "diana@external.com", "password_hash": "hash4", "is_active": True, "phone": "555-123-456"},
        {"username": "eve", "email": "eve@company.com", "password_hash": "hash5", "is_active": True, "phone": "111-222-333"}
    ]
    
    for user_data in test_users:
        db.insert_data("tools_demo", User, user_data)
    
    # Dodaj testowe logi
    test_logs = [
        {"level": "INFO", "message": "User login successful", "module": "auth", "user_id": 1},
        {"level": "WARNING", "message": "Invalid login attempt", "module": "auth", "user_id": None},
        {"level": "ERROR", "message": "Database connection failed", "module": "database", "user_id": None},
        {"level": "INFO", "message": "Data export completed", "module": "export", "user_id": 2},
        {"level": "DEBUG", "message": "Cache cleared", "module": "cache", "user_id": 3}
    ]
    
    for log_data in test_logs:
        db.insert_data("tools_demo", Log, log_data)
    
    print("âœ… Dane testowe przygotowane")
    return True

def example_logging_utils():
    """PrzykÅ‚ad uÅ¼ycia DatabaseLogger"""
    print("\n=== ðŸ“ Standaryzowane logowanie ===")
    
    # Pobierz logger
    logger = get_db_logger()
    
    # Logowanie operacji bazodanowych
    logger.log_database_operation("create_table", "tools_demo", True, "Created users table", 0.05)
    logger.log_database_operation("insert_data", "tools_demo", False, "Validation failed")
    
    # Logowanie wykonania zapytaÅ„
    logger.log_query_execution("SELECT", "users", 5, 0.012)
    logger.log_query_execution("UPDATE", "users", 2, 0.008)
    
    # Logowanie migracji
    logger.log_migration("tools_demo", 1, 2, True, 0.15)
    
    # Logowanie synchronizacji
    from models import User
    logger.log_sync("source_db", "target_db", [User], True, 25)
    
    # Logowanie bÅ‚Ä™dÃ³w z kontekstem
    try:
        raise ValueError("Test error")
    except Exception as e:
        logger.log_error("test_operation", e, {"user_id": 123, "action": "test"})
    
    print("âœ… PrzykÅ‚ady logowania wykonane")

def example_error_handling():
    """PrzykÅ‚ad obsÅ‚ugi bÅ‚Ä™dÃ³w"""
    print("\n=== âš ï¸ ObsÅ‚uga bÅ‚Ä™dÃ³w i walidacja ===")
    
    # UÅ¼ycie dekoratora obsÅ‚ugi bÅ‚Ä™dÃ³w
    @handle_database_errors("demo_operation")
    def risky_operation(will_fail=False):
        if will_fail:
            raise LuxDBError("Symulowany bÅ‚Ä…d", {"context": "demo"})
        return "Operacja zakoÅ„czona pomyÅ›lnie"
    
    # Test udanej operacji
    try:
        result = risky_operation(False)
        print(f"âœ… {result}")
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d: {e}")
    
    # Test nieudanej operacji
    try:
        result = risky_operation(True)
        print(f"âœ… {result}")
    except Exception as e:
        print(f"âŒ Przechwycony bÅ‚Ä…d: {type(e).__name__}: {e}")
    
    # ErrorCollector dla operacji batch
    from utils.error_handlers import ErrorCollector
    
    collector = ErrorCollector()
    
    # Symulacja operacji batch
    for i in range(10):
        collector.increment_total()
        if i % 3 == 0:  # Symuluj bÅ‚Ä™dy co trzeciÄ… operacjÄ™
            collector.add_error(ValueError(f"BÅ‚Ä…d w operacji {i}"), {"operation_id": i})
        else:
            collector.add_success()
    
    summary = collector.get_summary()
    print(f"ðŸ“Š Podsumowanie batch:")
    print(f"  - ÅÄ…cznie operacji: {summary['total_operations']}")
    print(f"  - Udanych: {summary['successful_operations']}")
    print(f"  - Nieudanych: {summary['failed_operations']}")
    print(f"  - WskaÅºnik sukcesu: {summary['success_rate']:.1f}%")

def example_sql_tools():
    """PrzykÅ‚ad narzÄ™dzi SQL"""
    print("\n=== ðŸ”§ NarzÄ™dzia SQL ===")
    
    db = get_db_manager()
    
    # 1. SQLQueryBuilder
    print("1. SQL Query Builder:")
    builder = SQLQueryBuilder()
    
    # Proste zapytanie
    query1 = (builder
              .select("username", "email", "is_active")
              .from_table("users")
              .where("is_active = 1")
              .order_by("username", "ASC")
              .limit(10)
              .build())
    
    print(f"Query 1: {query1}")
    
    # ZÅ‚oÅ¼one zapytanie z JOIN
    builder.reset()
    query2 = (builder
              .select("u.username", "COUNT(l.id) as log_count")
              .from_table("users u")
              .join("logs l", "u.id = l.user_id", "LEFT")
              .where("u.is_active = 1")
              .group_by("u.id", "u.username")
              .having("COUNT(l.id) > 0")
              .order_by("log_count", "DESC")
              .build())
    
    print(f"Query 2: {query2}")
    
    # 2. SQLTemplateEngine
    print("\n2. SQL Template Engine:")
    template_engine = SQLTemplateEngine()
    
    # UÅ¼yj gotowych szablonÃ³w
    templates = template_engine.get_common_queries()
    count_query = template_engine.render_template(
        templates["count_records"], 
        {"table": "users"}
    )
    print(f"Count query: {count_query}")
    
    # WÅ‚asny szablon
    custom_template = "SELECT * FROM {table} WHERE {field} = {value} AND created_at >= {date}"
    rendered = template_engine.render_template(custom_template, {
        "table": "users",
        "field": "is_active", 
        "value": 1,
        "date": datetime.now() - timedelta(days=7)
    })
    print(f"Custom query: {rendered}")
    
    # 3. SQLAnalyzer
    print("\n3. SQL Analyzer:")
    analyzer = SQLAnalyzer()
    
    test_queries = [
        "SELECT * FROM users WHERE is_active = 1",
        "SELECT u.*, COUNT(l.id) FROM users u LEFT JOIN logs l ON u.id = l.user_id GROUP BY u.id",
        "INSERT INTO users (username, email) VALUES ('test', 'test@example.com')",
        "UPDATE users SET is_active = 0 WHERE last_login < '2024-01-01'"
    ]
    
    for query in test_queries:
        analysis = analyzer.analyze_query(query)
        print(f"  Query: {query[:50]}...")
        print(f"    Type: {analysis['type']}, Read-only: {analysis['is_read_only']}")
        print(f"    Tables: {analysis['tables']}, Complexity: {analysis['complexity']}")
    
    # 4. Bezpieczne wykonywanie SQL
    print("\n4. Bezpieczne wykonywanie SQL:")
    try:
        if "tools_demo" in db.connection_pools:
            engine = db.connection_pools["tools_demo"].engine
            result = execute_sql_safely(engine, "SELECT COUNT(*) as user_count FROM users")
            print(f"  Liczba uÅ¼ytkownikÃ³w: {result[0]['user_count']}")
        else:
            print("  Baza tools_demo nie istnieje")
    except Exception as e:
        print(f"  BÅ‚Ä…d wykonania SQL: {e}")

def example_data_processing():
    """PrzykÅ‚ad przetwarzania danych"""
    print("\n=== ðŸ“Š Przetwarzanie danych ===")
    
    db = get_db_manager()
    
    # Pobierz dane testowe
    users = db.select_data("tools_demo", User)
    user_data = []
    for user in users:
        user_dict = {}
        for column in User.__table__.columns:
            user_dict[column.name] = getattr(user, column.name)
        user_data.append(user_dict)
    
    print(f"ðŸ“¥ ZaÅ‚adowano {len(user_data)} uÅ¼ytkownikÃ³w")
    
    # 1. DataFilter - filtrowanie
    print("\n1. Filtrowanie danych:")
    
    # Filtruj aktywnych uÅ¼ytkownikÃ³w
    active_users = DataFilter.filter_active_records(user_data)
    print(f"  Aktywni uÅ¼ytkownicy: {len(active_users)}")
    
    # Filtruj uÅ¼ytkownikÃ³w firmowych
    company_users = DataFilter.filter_by_field(user_data, "email", "@company.com", "contains")
    print(f"  UÅ¼ytkownicy firmowi: {len(company_users)}")
    
    # Filtruj uÅ¼ytkownikÃ³w z telefonem
    users_with_phone = DataFilter.filter_by_field(user_data, "phone", None, "is_not_null")
    print(f"  UÅ¼ytkownicy z telefonem: {len(users_with_phone)}")
    
    # 2. DataTransformer - transformacja
    print("\n2. Transformacja danych:")
    
    # Normalizuj emaile (maÅ‚e litery)
    normalized_data = DataTransformer.normalize_strings(user_data, ["email"])
    print("  âœ… Znormalizowano emaile")
    
    # Dodaj pole obliczone
    def compute_user_type(record):
        if "@company.com" in record.get("email", ""):
            return "Internal"
        elif "@external.com" in record.get("email", ""):
            return "External"
        return "Other"
    
    enriched_data = DataTransformer.add_computed_field(user_data, "user_type", compute_user_type)
    print("  âœ… Dodano pole user_type")
    
    # ZmieÅ„ nazwy pÃ³l
    renamed_data = DataTransformer.rename_fields(enriched_data, {
        "username": "login", 
        "is_active": "active_status"
    })
    print("  âœ… Zmieniono nazwy pÃ³l")
    
    # Wybierz tylko okreÅ›lone pola
    selected_data = DataTransformer.select_fields(enriched_data, ["username", "email", "user_type", "is_active"])
    print("  âœ… Wybrano pola: username, email, user_type, is_active")
    
    # 3. DataAggregator - agregacje
    print("\n3. Agregacje:")
    
    # Grupuj wedÅ‚ug typu uÅ¼ytkownika
    groups = DataAggregator.group_by(enriched_data, "user_type")
    for user_type, group in groups.items():
        print(f"  {user_type}: {len(group)} uÅ¼ytkownikÃ³w")
    
    # Policz wedÅ‚ug statusu aktywnoÅ›ci
    active_counts = DataAggregator.count_by_field(enriched_data, "is_active")
    print(f"  Aktywni/nieaktywni: {dict(active_counts)}")
    
    # 4. DataValidator - walidacja
    print("\n4. Walidacja danych:")
    
    # SprawdÅº wymagane pola
    missing_fields = DataValidator.validate_required_fields(user_data, ["username", "email"])
    if missing_fields:
        print(f"  âŒ Rekordy z brakujÄ…cymi polami: {len(missing_fields)}")
    else:
        print("  âœ… Wszystkie wymagane pola obecne")
    
    # SprawdÅº typy danych
    type_errors = DataValidator.validate_data_types(user_data, {
        "username": str,
        "email": str,
        "is_active": bool
    })
    if type_errors:
        print(f"  âŒ BÅ‚Ä™dy typÃ³w: {len(type_errors)}")
    else:
        print("  âœ… Wszystkie typy poprawne")
    
    # ZnajdÅº duplikaty
    duplicates = DataValidator.find_duplicates(user_data, ["email"])
    if duplicates:
        print(f"  âŒ Duplikaty: {len(duplicates)}")
    else:
        print("  âœ… Brak duplikatÃ³w")
    
    # 5. DataCleaner - czyszczenie
    print("\n5. Czyszczenie danych:")
    
    # UsuÅ„ rekordy z null w telefonie
    cleaned_data = DataCleaner.remove_nulls(user_data, ["phone"])
    print(f"  Rekordy bez null w telefonie: {len(cleaned_data)}")
    
    # Standaryzuj numery telefonÃ³w
    standardized_data = DataCleaner.standardize_phone_numbers(user_data)
    print("  âœ… Znormalizowano numery telefonÃ³w")
    
    # 6. Podsumowanie danych
    print("\n6. Podsumowanie danych:")
    summary = create_data_summary(user_data)
    print(f"  ðŸ“Š ÅÄ…czna liczba rekordÃ³w: {summary['total_records']}")
    print(f"  ðŸ“‹ Pola: {summary['fields']}")
    for field, stats in summary['field_stats'].items():
        print(f"    {field}: {stats['unique_count']} unikalnych, {stats['null_count']} null")

def example_export_import():
    """PrzykÅ‚ad eksportu i importu"""
    print("\n=== ðŸ’¾ Eksport i import danych ===")
    
    db = get_db_manager()
    
    # Pobierz dane do eksportu
    users = db.select_data("tools_demo", User)
    user_data = []
    for user in users:
        user_dict = {}
        for column in User.__table__.columns:
            user_dict[column.name] = getattr(user, column.name)
        user_data.append(user_dict)
    
    # UtwÃ³rz eksporter
    exporter = DataExporter()
    importer = DataImporter()
    
    # Eksport do rÃ³Å¼nych formatÃ³w
    with tempfile.TemporaryDirectory() as temp_dir:
        
        # 1. Eksport do JSON
        json_path = os.path.join(temp_dir, "users.json")
        exporter.export_to_json(user_data, json_path, pretty=True)
        print(f"âœ… Eksport do JSON: {json_path}")
        
        # SprawdÅº rozmiar pliku
        file_size = os.path.getsize(json_path)
        print(f"  ðŸ“ Rozmiar: {file_size} bajtÃ³w")
        
        # 2. Eksport do CSV
        csv_path = os.path.join(temp_dir, "users.csv")
        exporter.export_to_csv(user_data, csv_path)
        print(f"âœ… Eksport do CSV: {csv_path}")
        
        # 3. Eksport do XML
        xml_path = os.path.join(temp_dir, "users.xml")
        exporter.export_to_xml(user_data, xml_path, root_name="users", record_name="user")
        print(f"âœ… Eksport do XML: {xml_path}")
        
        # 4. Eksport do SQL
        sql_path = os.path.join(temp_dir, "users.sql")
        exporter.export_to_sql(user_data, "users_backup", sql_path, include_create=True)
        print(f"âœ… Eksport do SQL: {sql_path}")
        
        # 5. Import z JSON
        imported_data = importer.import_from_json(json_path)
        print(f"ðŸ“¥ Zaimportowano z JSON: {len(imported_data)} rekordÃ³w")
        
        # 6. Import z CSV
        imported_csv = importer.import_from_csv(csv_path)
        print(f"ðŸ“¥ Zaimportowano z CSV: {len(imported_csv)} rekordÃ³w")
        
        # 7. PorÃ³wnaj dane przed i po eksport/import
        original_usernames = {u['username'] for u in user_data}
        imported_usernames = {u['username'] for u in imported_data}
        
        if original_usernames == imported_usernames:
            print("âœ… Dane zgodne przed i po eksport/import")
        else:
            print("âŒ RÃ³Å¼nice w danych po eksport/import")
        
        # 8. PrzykÅ‚ad tworzenia nazwy backup
        from utils.export_tools import create_backup_filename
        backup_name = create_backup_filename("tools_demo", "json")
        print(f"ðŸ“¦ PrzykÅ‚adowa nazwa backup: {backup_name}")

def comprehensive_workflow():
    """Kompleksowy przepÅ‚yw pracy z wszystkimi narzÄ™dziami"""
    print("\n=== ðŸ”„ Kompleksowy przepÅ‚yw pracy ===")
    
    logger = get_db_logger()
    db = get_db_manager()
    
    try:
        # 1. Pobierz dane
        logger.log_database_operation("data_fetch", "tools_demo", True, "Fetching user data")
        users = db.select_data("tools_demo", User)
        
        # Konwertuj na sÅ‚owniki
        user_data = []
        for user in users:
            user_dict = {}
            for column in User.__table__.columns:
                user_dict[column.name] = getattr(user, column.name)
            user_data.append(user_dict)
        
        # 2. Waliduj dane
        validator = DataValidator()
        errors = validator.validate_required_fields(user_data, ["username", "email"])
        if errors:
            logger.logger.warning(f"Found {len(errors)} validation errors")
        
        # 3. PrzetwÃ³rz dane
        # Filtruj tylko aktywnych uÅ¼ytkownikÃ³w firmowych
        active_company_users = DataFilter.filter_by_field(
            DataFilter.filter_active_records(user_data),
            "email", "@company.com", "contains"
        )
        
        # Dodaj obliczone pola
        enriched_users = DataTransformer.add_computed_field(
            active_company_users, 
            "has_phone", 
            lambda r: r.get("phone") is not None
        )
        
        # 4. Agreguj statystyki
        aggregator = DataAggregator()
        phone_stats = aggregator.count_by_field(enriched_users, "has_phone")
        
        print(f"ðŸ“Š Aktywni uÅ¼ytkownicy firmowi: {len(enriched_users)}")
        print(f"ðŸ“± Z telefonem: {phone_stats.get(True, 0)}")
        print(f"ðŸ“µ Bez telefonu: {phone_stats.get(False, 0)}")
        
        # 5. Wyeksportuj wyniki
        if enriched_users:
            exporter = DataExporter()
            with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
                result_path = exporter.export_to_json(enriched_users, f.name)
                print(f"ðŸ’¾ Wyeksportowano wyniki do: {result_path}")
        
        # 6. Wygeneruj raport SQL
        builder = SQLQueryBuilder()
        report_query = (builder
                       .select("email", "username", "phone", "created_at")
                       .from_table("users")
                       .where("is_active = 1")
                       .where("email LIKE '%@company.com'")
                       .order_by("created_at", "DESC")
                       .build())
        
        print(f"ðŸ” Wygenerowane zapytanie raportu:")
        print(f"   {report_query}")
        
        logger.log_database_operation("workflow_complete", "tools_demo", True, 
                                    f"Processed {len(enriched_users)} records")
        
    except Exception as e:
        logger.log_error("comprehensive_workflow", e, {"step": "unknown"})
        raise

def main():
    """GÅ‚Ã³wna funkcja demonstracyjna"""
    print("ðŸš€ LuxDB - PrzykÅ‚ady zaawansowanych narzÄ™dzi")
    print("=" * 60)
    
    try:
        # Przygotuj dane testowe
        if not setup_test_data():
            return
        
        # Uruchom wszystkie przykÅ‚ady
        example_logging_utils()
        example_error_handling()
        example_sql_tools()
        example_data_processing()
        example_export_import()
        comprehensive_workflow()
        
        print("\nâœ… Wszystkie przykÅ‚ady zaawansowanych narzÄ™dzi zakoÅ„czone pomyÅ›lnie!")
        
    except Exception as e:
        print(f"\nâŒ BÅ‚Ä…d w przykÅ‚adach: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        # Zamknij poÅ‚Ä…czenia
        db = get_db_manager()
        db.close_all_connections()
        print("\nðŸ”’ ZamkniÄ™to wszystkie poÅ‚Ä…czenia")

if __name__ == "__main__":
    main()
